# Bachelor-Project
Scene-based Searching for Disabled People: Extracting Image Descriptions

In todayâ€™s digital age, searching for information online has become a ubiquitous part of
our daily lives. However, traditional text-based search engines can be challenging for
individuals with disabilities or those who do not speak the same language. Furthermore,
even for people who can use text-based searches, it can sometimes be difficult to articulate
their search query in words. In response to these challenges, scene-based searching
has emerged as an alternative approach that allows users to search for information using
images instead of text.

This project aims to develop a tool that enables people with disabilities and those who
do not speak the same language to search for information online through scene-based
searching. The tool is designed to extract image descriptions from a scene, providing
a more effective means of searching for information compared to traditional text-based
searches. The tool will be developed using a set of algorithms and
machine learning models that accurately analyze images and extract relevant information.

Google Colab was used to make the deep learning model, and the .py project file is linked. 
The Google Quick! Draw Dataset was used in this project, and the thesis describing everything in this project is also linked.
