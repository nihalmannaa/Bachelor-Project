# -*- coding: utf-8 -*-
"""Bach - Trial 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TMoKBsZbE-YIZlYP7xGHds7YRDS4vp3h

#Downloading the quick draw dataset
"""

from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D
from keras.utils import np_utils
from random import randint
import numpy as np
import os
import PIL
from PIL import Image, ImageTk, ImageDraw
from tkinter import *

!mkdir data

cd data

"""##Downloading 45 object categories """

!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crab.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crown.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/duck.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/feather.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy

!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy

!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy

!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy
!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy

cd ..

"""#Preprocessing the data"""

# Number of objects and object list
N_OBJ = 45
OBJ = {0: "Apple", 1: "Banana", 2: "Crab", 3: "Crown", 4: "Dog", 5: "Duck", 6: "Eye", 7: "Feather", 8: "Pizza", 9: "Tree", 10: "Pants", 11: "Umbrella", 12: "Face", 13: "Wheel", 14: "Cloud", 15: "Grapes", 16: "Bread", 17: "Book", 18: "Star", 19: "Drums", 20: "Sun", 21: "Laptop", 22: "Baseball Bat", 23: "Ladder", 24: "Eyeglasses", 25: "Dumbbell", 26: "Traffic Light", 27: "Wristwatch", 28: "Shovel", 29: "Table", 30: "Tennis Racquet", 31: "Chair", 32: "Headphones", 33: "Airplane", 34: "Snake", 35: "Lollipop", 36: "Power Outlet", 37: "Mushroom", 38: "Sword", 39: "Clock", 40: "Hot Dog", 41: "Syringe", 42: "Stop Sign", 43: "Mountain", 44: "Smiley Face"}

# Number of samples to take in each category
N = 2000

# Number of epochs
N_EPOCHS = 15

# Data files
files = ["apple.npy", "banana.npy", "crab.npy", "crown.npy", "dog.npy", "duck.npy", "eye.npy", "feather.npy", "pizza.npy", "tree.npy", "pants.npy", "umbrella.npy", "face.npy", "wheel.npy", "cloud.npy", "grapes.npy", "bread.npy", "book.npy", "star.npy", "drums.npy", "sun.npy", "laptop.npy", "baseball bat.npy", "ladder.npy", "eyeglasses.npy", "dumbbell.npy", "traffic light.npy", "wristwatch.npy", "shovel.npy", "table.npy", "tennis racquet.npy", "chair.npy", "headphones.npy", "airplane.npy", "snake.npy", "lollipop.npy", "power outlet.npy", "mushroom.npy", "sword.npy", "clock.npy", "hot dog.npy", "syringe.npy", "stop sign.npy", "mountain.npy", "smiley face.npy"]

def load(dir, reshaped, files):
    data = []
    for file in files:
        f = np.load(dir + file)
        if reshaped:
            new_f = []
            for i in range(len(f)):
                x = np.reshape(f[i], (28, 28))
                x = np.expand_dims(x, axis=0)
                x = np.reshape(f[i], (28, 28, 1))
                new_f.append(x)
            f = new_f
        data.append(f)
    return data


def normalize(data):
    return np.interp(data, [0, 255], [-1, 1])


def visualize(array):
    array = np.reshape(array, (28,28))
    img = Image.fromarray(array)
    return img


def set_limit(arrays, n):
    new = []
    for array in arrays:
        i = 0
        for item in array:
            if i == n:
                break
            new.append(item)
            i += 1
    return new


def make_labels(N1, N2):
    labels = []
    for i in range(N1):
        labels += [i] * N2
    return labels

# Reshaping the image to a 28x28 form
objects = load("data/", True, files)

# Limit no of samples in each class to N = 2000
objects = set_limit(objects, N)

# Normalize the values
objects = list(map(normalize, objects))

# Define the labels
labels = make_labels(N_OBJ, N)

# Split for training and testing
x_train, x_test, y_train, y_test = train_test_split(objects, labels, test_size=0.2)

# One hot encoding
Y_train = np_utils.to_categorical(y_train, N_OBJ)
Y_test = np_utils.to_categorical(y_test, N_OBJ)

from keras.preprocessing.image import ImageDataGenerator
# Data augmentation
train_datagen = ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')
test_datagen = ImageDataGenerator(rescale=1./255)

"""#The model"""

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(N_OBJ, activation='softmax'))

"""##Training and testing"""

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])


# Train
history = model.fit(np.array(x_train), np.array(Y_train), batch_size=32, epochs=N_EPOCHS, validation_split=0.1)

print("Training complete")

print("Evaluating model")

# Test
preds = model.predict(np.array(x_test))

score = 0
for i in range(len(preds)):
    if np.argmax(preds[i]) == y_test[i]:
        score += 1

print("Accuracy: ", ((score + 0.0) / len(preds)) * 100)

# Save
model.save("object_recog"+ ".h5")
print("Model saved")

import urllib.request
import os
import glob
import numpy as np
from tensorflow.python.keras import layers
from tensorflow import keras 
import tensorflow as tf
import matplotlib.pyplot as plt
from random import randint
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping

import matplotlib.pyplot as plt
from random import randint

from googleapiclient.discovery import build
from IPython.display import Image, display
from urllib.parse import urlparse, urlunparse
import random

import numpy as np
from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline  
idx = randint(0, len(x_test))
img = x_test[idx]
plt.imshow(img.squeeze())

pred = model.predict(np.expand_dims(img, axis=0))[0]
ind = (-pred).argsort()[:5]
latex = [OBJ[x] for x in ind]
print(latex)

"""##Adding my own input"""

import numpy as np
from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

uploaded = files.upload()

for fn in uploaded.keys():
 
  # Load the image
  img = load_img(fn, grayscale=True, target_size=(28, 28))

  # Convert the image to a numpy array
  img_array = img_to_array(img)

  # Normalize the image
  img_array /= 255.0

  # Reshape the image to match the input shape of the model
  img_array = np.expand_dims(img_array, axis=0)

  # Load the model
  num_classes = len(OBJ)
  # model = keras.models.load_model('quickdraw_model.h5')

  # Make a prediction
  pred = model.predict(img_array)[0]
  ind = (-pred).argsort()[:5]
  latex = [OBJ[x] for x in ind]
  print(latex)

import matplotlib.pyplot as plt
plt.imshow(img)

"""#Google search output"""

pip install google-api-python-client

from googleapiclient.discovery import build
from IPython.display import Image, display
import random

# Set up the API client
api_key = 'AIzaSyCZzP2ojVEDYp6zOCDoNxkSZEtsm4fjkLk'
cse_id = '46b351383853340c8'
service = build('customsearch', 'v1', developerKey=api_key)

# Search for images

# ind = (-pred).argsort()[:5]
# latex = [class_names[x] for x in ind]
print(latex)

# output_list = ['cat', 'dog', 'penguin', 'apple', 'key']
image_urls = {}
for keyword in latex:
    search_query = keyword + ' images'
    res = service.cse().list(
        q=search_query,
        cx=cse_id,
        searchType='image'
    ).execute()
    if 'items' in res:
        item_count = len(res['items'])
        rand_index = random.randint(0, item_count - 1)
        image_urls[keyword] = res['items'][rand_index]['link']

# Display the images for each keyword
for keyword, image_url in image_urls.items():
    display(Image(url=image_url, width=150))
    print(keyword)

from googleapiclient.discovery import build
from IPython.display import Image, display
import random

# Set up the API client
api_key = 'AIzaSyCZzP2ojVEDYp6zOCDoNxkSZEtsm4fjkLk'
cse_id = '46b351383853340c8'
service = build('customsearch', 'v1', developerKey=api_key)

# Search for images

# ind = (-pred).argsort()[:5]
# latex = [class_names[x] for x in ind]
print(latex)

# output_list = ['cat', 'dog', 'penguin', 'apple', 'key']
image_urls = {}
num_images_per_category = 4  # Set the desired number of images per category

for keyword in latex:
    search_query = keyword + ' images'
    res = service.cse().list(
        q=search_query,
        cx=cse_id,
        searchType='image',
        num=num_images_per_category  # Set the number of images to retrieve
    ).execute()
    if 'items' in res:
        items = res['items'][:num_images_per_category]  # Select the desired number of images
        image_urls[keyword] = [item['link'] for item in items]

# Display the images for each keyword
for keyword, image_urls_list in image_urls.items():
    print(keyword)
    for image_url in image_urls_list:
        display(Image(url=image_url, width=150))

"""#Plotting model results"""

from tensorflow.keras.models import load_model
import numpy as np
from numpy import asarray
from tkinter import *
import PIL
import os
from PIL import Image, ImageTk, ImageDraw
from skimage import data, io
from skimage.transform import resize

import matplotlib.pyplot as plt

# Plot the model results
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')

plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()